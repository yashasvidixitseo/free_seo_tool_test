# -*- coding: utf-8 -*-
"""seo free tool test

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14CO3zn2FQ2lI5tm-errHRav5LuGy1G5s
"""

pip install requests beautifulsoup4 nltk

import nltk
nltk.download("punkt")
nltk.download("stopwords")

import requests
from bs4 import BeautifulSoup
from collections import Counter
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import string

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
}

def fetch_page(url):
    response = requests.get(url, headers=HEADERS, timeout=10)
    response.raise_for_status()
    return BeautifulSoup(response.text, "html.parser")

def analyze_seo(url):
    soup = fetch_page(url)

    seo_data = {}

    # 1️⃣ Meta Title
    title = soup.find("title")
    seo_data["meta_title"] = title.text.strip() if title else "Missing"

    # 2️⃣ Meta Description
    meta_desc = soup.find("meta", attrs={"name": "description"})
    seo_data["meta_description"] = (
        meta_desc["content"].strip() if meta_desc else "Missing"
    )

    # 3️⃣ Meta Keywords (old but still check)
    meta_keys = soup.find("meta", attrs={"name": "keywords"})
    seo_data["meta_keywords"] = (
        meta_keys["content"].strip() if meta_keys else "Missing"
    )

    # 4️⃣ Headings
    seo_data["h1"] = [h.text.strip() for h in soup.find_all("h1")]
    seo_data["h2"] = [h.text.strip() for h in soup.find_all("h2")]

    # 5️⃣ Image ALT check
    images = soup.find_all("img")
    missing_alt = [img.get("src") for img in images if not img.get("alt")]
    seo_data["images_missing_alt"] = len(missing_alt)

    # 6️⃣ Keyword Extraction from Content
    body_text = soup.body.get_text(" ", strip=True).lower()
    tokens = word_tokenize(body_text)

    stop_words = set(stopwords.words("english"))
    clean_words = [
        word for word in tokens
        if word.isalpha()
        and word not in stop_words
        and len(word) > 2
    ]

    keyword_freq = Counter(clean_words).most_common(10)
    seo_data["top_keywords"] = keyword_freq

    return seo_data

import nltk
nltk.download('punkt_tab')
nltk.download('stopwords')

url = "https://www.famousbirthdays.com/people/bill-hader.html"
result = analyze_seo(url)

print("\nMETA TITLE:")
print(result["meta_title"])

print("\nMETA DESCRIPTION:")
print(result["meta_description"])

print("\nMETA KEYWORDS:")
print(result["meta_keywords"])

print("\nH1 TAGS:")
print(result["h1"])

print("\nH2 TAGS:")
print(result["h2"])

print("\nIMAGES MISSING ALT:")
print(result["images_missing_alt"])

print("\nTOP KEYWORDS:")
for k, v in result["top_keywords"]:
    print(k, "→", v)

